"""
ë¶„ì„ API
- POST /analyze  : { "texts": [...], "model_name"?, "centroids_path"? }
- GET  /healthz  : í—¬ìŠ¤ì²´í¬
- ê¸°ë³¸ ì‹¤í–‰      : python -m AI.prompt_analyzer.analyzer_api 
- ë¡œì»¬ ì…€í”„í…ŒìŠ¤íŠ¸: python -m AI.prompt_analyzer.analyzer_api --selftest
"""

import os
import json
import datetime
from pathlib import Path
from typing import Any, Dict, Tuple

import numpy as np
import torch

# --- import ---
try:
    from AI.prompt_analyzer.fluency import compute_fluency
    from AI.prompt_analyzer.persistence import compute_persistence
except Exception:
    from prompt_analyzer.fluency import compute_fluency  # type: ignore
    from prompt_analyzer.persistence import compute_persistence  # type: ignore

from transformers import AutoTokenizer, AutoModel

# Flask
from flask import Flask, request, jsonify
from flask_cors import CORS

# KoBERT
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")
os.environ.setdefault("TRANSFORMERS_NO_TF", "1")
os.environ.setdefault("TRANSFORMERS_NO_FLAX", "1")
os.environ.setdefault("TRANSFORMERS_NO_JAX", "1")

# ê¸°ë³¸ ì„¼íŠ¸ë¡œì´ë“œ ê²½ë¡œ
_THIS_DIR = Path(__file__).resolve().parent
_DEFAULT_CENTROIDS_CANDIDATES = [
    _THIS_DIR / "DPDT" / "models" / "kmeans_k100" / "centroids.npy",
    _THIS_DIR.parent / "DPDT" / "models" / "kmeans_k100" / "centroids.npy",
    Path("AI/DPDT/models/kmeans_k100/centroids.npy"),
    Path("DPDT/models/kmeans_k100/centroids.npy"),
]

def _default_centroids_path() -> str:
    for p in _DEFAULT_CENTROIDS_CANDIDATES:
        if Path(p).exists():
            return str(p)
    return "DPDT/models/kmeans_k100/centroids.npy"

DEFAULT_CENTROIDS_PATH = _default_centroids_path()

_TOKENIZER = None
_MODEL = None
_DEVICE = None
_CENTROIDS = None          
_CENTROIDS_TAG = None      

def _ensure_resources(model_name: str, centroids_path: str) -> None:
    global _TOKENIZER, _MODEL, _DEVICE, _CENTROIDS, _CENTROIDS_TAG

    if _TOKENIZER is None or _MODEL is None:
        _TOKENIZER = AutoTokenizer.from_pretrained(model_name, use_fast=False)
        _MODEL = AutoModel.from_pretrained(model_name).eval()
        _DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        _MODEL.to(_DEVICE)

    cp = Path(centroids_path)
    tag = (cp.resolve().as_posix() if cp.exists() else str(cp))
    if (_CENTROIDS is None) or (_CENTROIDS_TAG != tag):
        if not cp.exists():
            raise FileNotFoundError(f"centroids not found: {cp}")
        arr = np.load(cp)
        if arr.dtype != np.float32:
            arr = arr.astype(np.float32, copy=False)
        _CENTROIDS = arr
        _CENTROIDS_TAG = tag

def _call_metric(func, texts, centroids_path: str, model_name: str) -> Tuple[float, float, float, float]:
    try:
        val = func(
            texts,
            centroids_path,
            model_name,
            resources={
                "tokenizer": _TOKENIZER,
                "model": _MODEL,
                "device": _DEVICE,
                "centroids": _CENTROIDS,
            },
        )
    except TypeError:
        val = func(texts, centroids_path, model_name)

    if isinstance(val, tuple) and len(val) >= 4:
        score, S, K, C = val[:4]
        return float(score), float(S), float(K), float(C)
    else:
        return float(val), 0.0, 0.0, 0.0

# ì™¸ë¶€ ê³µê°œ ë‹¨ì¼ API 
def analyze_from_api(
    texts,
    centroids_path: str = DEFAULT_CENTROIDS_PATH,
    model_name: str = "skt/kobert-base-v1",
) -> Dict[str, Any]:
    print("ğŸ“¥ analyze_from_api ì§„ì…", flush=True)

    if not texts:
        print("âš ï¸ ì…ë ¥ ë¬¸ì¥ ì—†ìŒ", flush=True)
        return {
            "error": "ë¶„ì„í•  ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.",
            "status": 400,
            "timestamp": datetime.datetime.now().isoformat(),
        }

    try:
        _ensure_resources(model_name, centroids_path)

        print("ğŸ§  compute_fluency ì‹œì‘", flush=True)
        flu_score, fS, fK, fC = _call_metric(compute_fluency, texts, centroids_path, model_name)
        print("âœ… compute_fluency ì™„ë£Œ:", flu_score, flush=True)

        print("ğŸ§  compute_persistence ì‹œì‘", flush=True)
        pers_score, pS, pR, pF = _call_metric(compute_persistence, texts, centroids_path, model_name)
        print("âœ… compute_persistence ì™„ë£Œ:", pers_score, flush=True)

        creativity_score = (flu_score * 0.5 + pers_score * 0.5)
        print("ğŸ¯ ìµœì¢… ì ìˆ˜:", creativity_score, flush=True)

        return {
            "status": 200,
            "message": "ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "results": [
                {
                    "creativity": round(creativity_score, 4),
                    "fluency": round(flu_score, 4),
                    "persistence": round(pers_score, 4),
                    "fluency_skc": {
                        "fluency_s": round(fS, 4),
                        "fluency_k": round(fK, 4),
                        "fluency_c": round(fC, 4),
                    },
                    "persistence_srf": {
                        "persistence_s": round(pS, 4),
                        "persistence_r": round(pR, 4),
                        "persistence_f": round(pF, 4)
                    }
                }
            ]
        }



    except Exception as e:
        print("âŒ ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ:", e, flush=True)
        return {
            "error": str(e),
            "status": 500,
            "timestamp": datetime.datetime.now().isoformat(),
        }

# Flask ì•± (ì—”ë“œí¬ì¸íŠ¸)
app = Flask(__name__)
CORS(app)

@app.route("/healthz", methods=["GET"])
def healthz():
    return jsonify({"status": "ok"}), 200

@app.route("/analyze", methods=["POST"], strict_slashes=False)
def analyze_route():
    try:
        data = request.get_json(force=True) or {}
    except Exception:
        return jsonify({"error": "invalid JSON"}), 400

    # 1) chatId ì¶”ì¶œ (í•„ìš”í•˜ë©´ ì‘ë‹µì—ë„ ê·¸ëŒ€ë¡œ í¬í•¨ ê°€ëŠ¥)
    chat_id = data.get("chatId") or data.get("chat_id")

    # 2) promptContents â†’ texts ë¡œ ë³€í™˜
    texts = data.get("promptContents", [])

    # ë¬¸ìì—´ì´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(texts, str):
        texts = [texts]
    elif isinstance(texts, dict):
        # promptContentsê°€ [{"content":"..."}] ê°™ì€ êµ¬ì¡°ì¼ ê²½ìš° content í‚¤ êº¼ë‚´ê¸°
        val = texts.get("content") or texts.get("text") or texts.get("value")
        texts = [val] if val else []
    elif isinstance(texts, (list, tuple)):
        norm = []
        for x in texts:
            if isinstance(x, dict):
                v = x.get("content") or x.get("text") or x.get("value")
                if v:
                    norm.append(str(v))
            elif isinstance(x, str):
                norm.append(x)
        texts = norm

    if not texts:
        return jsonify({"error": "texts empty", "status": 400}), 400
    
    model_name = data.get("model_name", "skt/kobert-base-v1")
    centroids_path = data.get("centroids_path", DEFAULT_CENTROIDS_PATH)

    result = analyze_from_api(texts, centroids_path=centroids_path, model_name=model_name)

    # ì‘ë‹µì— chatId í¬í•¨ì‹œí‚¤ê¸° (í•„ìš”ì‹œ)
    if chat_id is not None:
        result["chatId"] = chat_id

    code = result.get("status", 200)
    return jsonify(result), int(code)


# ë©”ì¸: ê¸°ë³¸ì€ ì„œë²„ ì‹¤í–‰, --selftest ì‹œ ìƒ˜í”Œ ì¶œë ¥ í›„ ì¢…ë£Œ
if __name__ == "__main__":
    import argparse

    ap = argparse.ArgumentParser()
    ap.add_argument("--host", default="0.0.0.0")
    ap.add_argument("--port", type=int, default=int(os.environ.get("PORT", "5000")))
    ap.add_argument("--debug", action="store_true", default=True)
    ap.add_argument("--selftest", action="store_true", help="ìƒ˜í”Œ ë¬¸ì¥ìœ¼ë¡œ ë¡œì»¬ ë¶„ì„ë§Œ ìˆ˜í–‰í•˜ê³  ì¢…ë£Œ")
    ap.add_argument("--centroids", default=DEFAULT_CENTROIDS_PATH, help="override centroids path")
    ap.add_argument("--model", default="skt/kobert-base-v1")
    args = ap.parse_args()

    if args.selftest:
        samples = [
            "ì•ˆê°œ ë‚€ ìˆ²ê¸¸ì„ í™€ë¡œ ê±·ëŠ” ì‚¬ëŒ",
            "ê°•ì•„ì§€ê°€ ë›°ë…¸ëŠ” í‘¸ë¥¸ ë“¤íŒ",
            "ë„ì‹œì˜ ë°¤ê±°ë¦¬ë¥¼ ë‹¬ë¦¬ëŠ” ìë™ì°¨",
            "ì•„ì´ë“¤ì´ ê³µì›ì—ì„œ ë›°ì–´ë…¸ëŠ” ì¥ë©´",
            "ë°”ë‹·ê°€ì—ì„œ ì„œí•‘ì„ ì¦ê¸°ëŠ” ì²­ë…„",
            "ì±…ìƒ ìœ„ì— í¼ì³ì§„ ê³ ì„œì™€ ë§Œë…„í•„",
            "í•˜ëŠ˜ ë†’ì´ ë–  ìˆëŠ” ì—´ê¸°êµ¬",
            "ë°¤í•˜ëŠ˜ì„ ìˆ˜ë†“ëŠ” ë¶ˆê½ƒë†€ì´",
            "ìœ ë¦¬ì°½ ë„ˆë¨¸ë¡œ ë¹„ê°€ ë‚´ë¦¬ëŠ” í’ê²½",
            "ì‚° ì •ìƒì—ì„œ ì¼ì¶œì„ ë°”ë¼ë³´ëŠ” ë“±ì‚°ê°",
        ]
        out = analyze_from_api(samples, centroids_path=args.centroids, model_name=args.model)
        print(json.dumps(out, ensure_ascii=False, indent=2))
    else:
        app.run(host=args.host, port=args.port, debug=args.debug)
