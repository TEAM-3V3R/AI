from flask import Flask, request, jsonify
from konlpy.tag import Okt
from collections import Counter
from sentence_transformers import SentenceTransformer
import torch
import json

app = Flask(__name__)

# ëª¨ë¸ ë° í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
model = SentenceTransformer("BM-K/KoSimCSE-roberta")
okt = Okt()

# ë™ìŒì´ì˜ì–´ ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°
with open("data/homonym_embeddings.json", "r", encoding="utf-8") as f:
    homonym_embeddings = json.load(f)

# í˜•íƒœì†Œ ë¶„ì„
def analyze_pos(text):
    # okt = Okt()
    tokens = okt.pos(text, stem=True)
    pos_tags = [tag for _, tag in tokens]
    total_count = len(pos_tags)
    counter = Counter(pos_tags)
    ratios = {tag: round(count / total_count, 3) for tag, count in counter.items()}
    return tokens, ratios

# ë¬¸ë§¥ ì¶”ì¶œ
def extract_context(tokens, index, window=2):
    start = max(index - window, 0)
    end = min(index + window + 1, len(tokens))
    return ' '.join([word for word, _ in tokens[start:end]])

# ë™ìŒì´ì˜ì–´ ì˜ë¯¸ ì¶”ë¡ 
def get_best_sense_by_example_avg(context_embedding, senses):
    best_sim = -1
    best_sense = None
    for sense in senses:
        examples = sense.get("examples", [])
        if not examples:
            continue
        example_embeddings = model.encode(examples, convert_to_tensor=True)
        avg_example_embedding = torch.mean(example_embeddings, dim=0)
        definition_embedding = model.encode(sense["definition"], convert_to_tensor=True)
        combined = torch.mean(torch.stack([avg_example_embedding, definition_embedding]), dim=0)
        sim = torch.nn.functional.cosine_similarity(context_embedding, combined, dim=0).item()
        if sim > best_sim:
            best_sim = sim
            best_sense = sense
    return best_sense, best_sim

# ìŠ¤í”„ë§ì—ì„œ ë°›ëŠ” POST ìš”ì²­ ì²˜ë¦¬
@app.route("/process", methods=["POST"])
def process_prompt():
    data = request.get_json()
    
    # Springì—ì„œëŠ” "promptContent"ë¡œ ë³´ëƒ„
    prompt = data.get("promptContent", "").strip()

    print(f"[ğŸ“¥ ë°›ì€ í”„ë¡¬í”„íŠ¸]: {prompt}", flush=True)

    if not prompt:
        return jsonify({"error": "No prompt content provided."}), 400

    # í˜•íƒœì†Œ ë¶„ì„ ë° ì˜ë¯¸ ì¶”ë¡  (ì‹¤ì œë¡œ ê²°ê³¼ ë°˜í™˜ì€ ì•ˆí•¨)
    tokens, pos_ratios = analyze_pos(prompt)

    for i, (word, tag) in enumerate(tokens):
        if word not in homonym_embeddings:
            continue

        context = extract_context(tokens, i)
        context_embedding = model.encode(context, convert_to_tensor=True)
        senses = homonym_embeddings[word]
        best_sense, _ = get_best_sense_by_example_avg(context_embedding, senses)

        # ì‹¤ì œ ì‘ë‹µì— í¬í•¨í•˜ì§„ ì•Šì§€ë§Œ ë‚´ë¶€ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•¨

    # ì„±ê³µ ì‘ë‹µë§Œ ë°˜í™˜
    return jsonify({
        "message": "í”„ë¡¬í”„íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "status": 200
    }), 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
